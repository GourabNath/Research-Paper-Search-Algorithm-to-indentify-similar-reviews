{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK package version :  3.2.1\n",
      "Working directory :  C:\\Users\\Ronny\\Documents\\CAP\\Stage1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(\"NLTK package version : \",nltk.__version__)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "print(\"Working directory : \",os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Ronny\\\\Documents\\\\CAP\\\\Functions\\\\Research-Paper-Search-Algorithm-to-indentify-similar-reviews-master\\\\Codes\")\n",
    "from ReviewCleaningFunction import clean_review\n",
    "from Nouns import get_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Ronny\\Documents\\CAP\\Functions\\transaction_doc.csv\")\n",
    "reviews = data.Review_text\n",
    "rev1 = reviews.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noun_list = []\n",
    "for _i in reviews:\n",
    "    clean = clean_review(_i)\n",
    "    tmp1 = get_nouns(clean)\n",
    "    if len(tmp1) > 0:\n",
    "        noun_list.append(list(set(tmp1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#header = 'Noun'\n",
    "#np.savetxt(\"noun_list.csv\", noun_list, delimiter=\",\", fmt='%s', header=header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing python packages\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Importing mlxtend packages for sparse matrix & apriori\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Preparing the dataframe as list of list for the sparse matrix\n",
    "df_list = []\n",
    "for i in noun_list:\n",
    "    for j in i:\n",
    "        df_list.append(j.split(','))\n",
    "\n",
    "#print(df_list)\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary1 = te.fit(noun_list).transform(noun_list)\n",
    "df1 = pd.DataFrame(te_ary1, columns=te.columns_)\n",
    "#df1.to_csv(\"sparsematrix.csv\")\n",
    "#print(df1)\n",
    "\n",
    "apr = apriori(df1, min_support=0.01, use_colnames=True, max_len=1)\n",
    "sorted_apr = apr.sort_values(['support'], ascending=False)\n",
    "\n",
    "print(sorted_apr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sorted_apr.to_csv(\"sorted_apr_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pandas\n",
    "#df = pandas.DataFrame(data={\"noun\": noun_list})\n",
    "#df.to_csv(\"./file.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing python packages\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Importing mlxtend packages for sparse matrix & apriori\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "def apriori_func(noun_listoflist,maxlen):\n",
    "    # Preparing the dataframe as list of list for the sparse matrix\n",
    "    df_list = []\n",
    "    for i in noun_list:\n",
    "        for j in i:\n",
    "            df_list.append(j.split(','))\n",
    "\n",
    "    te = TransactionEncoder()\n",
    "    te_ary1 = te.fit(noun_list).transform(noun_list)\n",
    "    df1 = pd.DataFrame(te_ary1, columns=te.columns_)\n",
    "    \n",
    "    apr = apriori(df1, min_support=0.01, use_colnames=True, max_len=maxlen)\n",
    "    sorted_apr = apr.sort_values(['support'], ascending=False)\n",
    "\n",
    "    return sorted_apr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(apriori_func(reviews,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
